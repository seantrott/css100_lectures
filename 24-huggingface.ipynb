{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "565fd595",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# LLMs in Python with `transformers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f3ec1503-eca7-4d25-8115-5ebeb684c36c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58997db4-551c-4a50-973a-e8fc2a4d2df2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Lecture plan\n",
    "\n",
    "- Review: **Large Language Models**.\n",
    "- Introduction to the `transformers` package.\n",
    "   - Tokenizers.\n",
    "   - A \"small\" LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649458e7-509c-4603-9862-fc9f103cedae",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Review: LLMs\n",
    "\n",
    "> **Large language models (LLMs)** are neural networks trained to predict the *next token*.\n",
    "\n",
    "- LLMs use various architectures, from **recurrent neural networks** to **transformers**.\n",
    "- So far, we've focused on the *theoretical underpinnings*, e.g., the **attention mechanism**.\n",
    "- Now, we'll discuss (briefly) how to work with *pre-trained LLMs* in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df77543d-b069-437d-805d-66eb7518f436",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## The `transformers` package\n",
    "\n",
    "> The [*huggingface* `transformers` package](https://huggingface.co/docs/transformers/en/index) is a Python package containing an API and tools to work with *pre-trained LLMs*.\n",
    "\n",
    "- The package is named after the **transformer** architecture, one of the most popular LLM architectures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669f62d4-701a-4afc-b673-a0dd614efb5d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### What is a pre-trained LLM?\n",
    "\n",
    "> A **pre-trained LLM** is an LLM that has already been trained on a large corpus.\n",
    "\n",
    "- Training LLMs is extremely costly.\n",
    "- Thus, many researchers rely on *pre-trained* models, i.e., systems that dedicated research teams have already built.\n",
    "- This has its own limitations (less freedom in how we train them), but does simplify the process.\n",
    "- `transformers` has a bunch (>600K) of pre-trained models to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e5eacc-cdb9-4e0b-96e6-f9e21193c1f8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### What do you need to know/use?\n",
    "\n",
    "Suppose you want to use a model from `transformers` to calculate the *probability* of words in context. You'll need:\n",
    "\n",
    "- A **tokenizer** for that model.\n",
    "- The actual **pre-trained model**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b088fd-500a-4f44-910b-78aea0aa16a4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Tokenizers!\n",
    "\n",
    "> **Tokenization** is the process of *segmenting* a string into smaller chunks or units.\n",
    "\n",
    "- We discussed a number of *tokenization* methods earlier this quarter.\n",
    "- LLMs rely on their own **tokenizers**, which learn to segment text.\n",
    "- A number of different *training procedures* for tokenization, such as [byte-pair encoding](https://huggingface.co/learn/llm-course/en/chapter6/5).\n",
    "   - *tl;dr*: recursively learn longer and longer tokens by finding the most common substrings.\n",
    "- Language models technically operate over *tokens* (IDs), not raw strings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f52e621-f6de-4bba-831b-7794cefb77b2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Importing a tokenizer\n",
    "\n",
    "- As illustration, we'll use the [*Pythia-160m* tokenizer](https://huggingface.co/EleutherAI/pythia-160m).\n",
    "- *Pythia-160m* is part of a [\"suite\" of language models created by EleutherAI](https://arxiv.org/abs/2304.01373).\n",
    "- To load a tokenizer, use:\n",
    "\n",
    "```\n",
    "AutoTokenizer.from_pretrained({MODEL_PATH})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b3aa2a8-700d-45ba-a32c-08b3a4ef054d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-160m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1403ed-5d0d-46d6-9f94-ac664b2b66f8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Using a tokenizer\n",
    "\n",
    "- To *use* a tokenizer, pass a `str` into the tokenizer object.\n",
    "- This returns a dictionary with the **token IDs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac6f6ba6-b1ff-4b9d-94bd-73e62bf51094",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 783, 1436]]), 'attention_mask': tensor([[1, 1]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase = \"the person\"\n",
    "inputs = tokenizer(phrase, return_tensors=\"pt\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2300a7dd-7250-4a94-8961-01b7706f8e71",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### What *are* these tokens anyway?\n",
    "\n",
    "- Each *token* maps onto a specific *ID* in the model's vocabulary.\n",
    "- Notice that some tokens start with a strange `\"Ġ\"` character. What do you think that is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db25d4a4-88d7-4530-a522-9a81889bbd5d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(783)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a32c64a-ec00-49ce-b91d-dbf41def9eee",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ġperson'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### What do you think this Ġ represents?\n",
    "tokenizer.convert_ids_to_tokens(1436)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b770606d-8ae7-4113-b0c8-ffb007c309dc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Understanding tokens\n",
    "\n",
    "- The `\"Ġ\"` character is the tokenizer's way of indicating that this token is a *new word*, i.e., it follows a whitespace (` `) character.\n",
    "- Some tokens aren't separate words, they're just *part* of words!\n",
    "- It all comes down to how the tokenizer **tokenizes** the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89c1ba6e-2f32-4018-a101-7f49f32394dd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[6148,  371,  763]]), 'attention_mask': tensor([[1, 1, 1]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"vanquish\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "526d0099-3ce4-426c-871d-fcda82785f76",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'van'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(6148)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "948984de-ffff-477f-b20c-68782717dfbc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'qu'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(371)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "692265cc-a30e-4360-943d-116d8d03385a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ish'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(763)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e893008-fbf6-44c8-b2f2-894f767f698a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Check-in\n",
    "\n",
    "Can you identify other words that are tokenized into multiple tokens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc3a7ba5-7b63-4f49-8032-333a8df6c864",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd17f73-ffda-400c-b677-a2163a327321",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Tokenizing entire sentences\n",
    "\n",
    "- You can tokenize entire sentences (or even multiple sentences).\n",
    "- The only limitation (downstream) will be the size of the model's **context window**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2757b003-f558-4b3a-b8be-6e30363436c7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentence = \"The students enjoyed the class.\"\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77c1378e-e7f5-478f-8bf4-ba6e183b47a6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'Ġstudents', 'Ġenjoyed', 'Ġthe', 'Ġclass', '.']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the tokens?\n",
    "tokens = [tokenizer.convert_ids_to_tokens(i) for i in inputs['input_ids']]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12479399-e686-4575-82bf-e19113595dcd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Language models\n",
    "\n",
    "In `transformers`, the [`model`](https://huggingface.co/transformers/v3.0.2/main_classes/model.html) class can be used to:\n",
    "\n",
    "- Calculate the **probability** of words in a sequence.\n",
    "- Investigate the **hidden states** of a model.\n",
    "- Investigate the **attention patterns** of a model.\n",
    "- **Generate** new text by sampling from the model's probability distribution.\n",
    "\n",
    "We'll explore examples of all these in turn!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d7f28f-3279-4a67-bd0f-5204edc97843",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Instantiating a language model\n",
    "\n",
    "- A pretrained model can be *instantiated* by passing in the HuggingFace path.\n",
    "- `output_hidden_states = True` means we can inspect the model activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2f3f31c-6a40-43ef-919a-1570b5efbb91",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoXForCausalLM(\n",
       "  (gpt_neox): GPTNeoXModel(\n",
       "    (embed_in): Embedding(50304, 768)\n",
       "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (embed_out): Linear(in_features=768, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/pythia-160m\",\n",
    "                                 output_hidden_states = True)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202c2ec8-5c76-46fa-ba49-7c8a47551034",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Inspecting our model parameters\n",
    "\n",
    "- An LM is fundamentally a bunch of **weight matrices**.\n",
    "- Recall that each layer consists of a *transformer block*.\n",
    "- We can directly access those weights (though it's hard to interpret them!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41ff493f-91b6-4238-b94c-627e108d7d34",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=2304, bias=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### The QKV matrices for layer 2\n",
    "model.gpt_neox.layers[1].attention.query_key_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7b5e165-4518-4b13-9037-e9fc68e3fcd5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 4.6967e-02, -4.0970e-03, -1.2794e-02,  ..., -6.6284e-02,\n",
       "         -1.6235e-02, -1.9302e-02],\n",
       "        [ 5.0476e-02, -3.3203e-02, -1.2825e-02,  ..., -3.7415e-02,\n",
       "         -1.1215e-02, -4.0192e-02],\n",
       "        [-9.6359e-03,  5.3024e-03,  8.3008e-03,  ..., -6.0349e-03,\n",
       "         -2.7252e-02, -8.1940e-03],\n",
       "        ...,\n",
       "        [ 1.7593e-02,  2.1515e-03,  2.9984e-03,  ..., -1.2329e-02,\n",
       "         -2.5528e-02,  1.9958e-02],\n",
       "        [ 1.9897e-02, -2.5940e-02,  5.7869e-03,  ..., -2.4902e-02,\n",
       "          6.9351e-03,  7.2708e-03],\n",
       "        [-1.4641e-02,  1.8723e-02,  9.0182e-05,  ...,  2.8763e-02,\n",
       "         -1.4030e-02, -1.1425e-03]], requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Actual weights\n",
    "model.gpt_neox.layers[1].attention.query_key_value.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0bf5c6-d959-4209-a748-bed08863ecb7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Running the model\n",
    "\n",
    "A pretrained model can be run in **inference mode**, i.e., without updating parameters.\n",
    "- First, tokenize a sentence.\n",
    "- Then, pass sentence into model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8404ddfe-c63a-45e5-9f16-c3e02124bff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tokenize sentence\n",
    "sentence = \"I like salt and\"\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f73c5ede-4098-45db-bd77-050fd91eac65",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pass into model\n",
    "with torch.no_grad():\n",
    "    output = model(**inputs, output_attentions = True,\n",
    "                  return_dict = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5ffe41-e1b1-4e60-accd-f62ed2896784",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Inspecting our output\n",
    "\n",
    "Given our output, we can inspect:\n",
    "\n",
    "- The `logits`: useful for figuring out the *probability* assigned to particular words by the model.\n",
    "- The `hidden_states`: useful for figuring out the *representation* of different tokens at each layer of the model.\n",
    "- The `attention` weights: useful for figuring out where the model is \"looking at\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb01c388-caa3-425c-ab10-8189087f7bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 50304])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Logits for each token\n",
    "output.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c16509b1-b388-41b1-900a-d23972570db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 768])\n",
      "torch.Size([1, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "### Hidden states for each token for each layer\n",
    "print(output.hidden_states[0].shape)\n",
    "print(output.hidden_states[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e592623c-3f36-465b-82c4-83852a1e2305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Attentions for each token/token for each layer/head\n",
    "len(output.attentions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23db0dce-f117-475f-9783-8819246f011d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Inspecting the `logits`\n",
    "\n",
    "- Technically, models allow sentences to be run in **batches**.\n",
    "- We've only passed in one sentence, so we just have logits for that one sentence.\n",
    "- The logits at each position represent the model's **predictions** at that token position.\n",
    "- To access what word the model thinks is *most likely next*, we can look at the logits for the final position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6fea5272-0d94-4770-9155-c22f50ca2d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 50304])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Focus on sentence logits\n",
    "sentence_logits = output.logits[0]\n",
    "sentence_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33ca529f-cf35-41b1-a22f-032b9813af20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50304])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Last token logits\n",
    "last_token_logits = sentence_logits[-1]\n",
    "last_token_logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c7febe-f381-4c0e-96d2-dae6cc338769",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### What word is most likely?\n",
    "\n",
    "- Let's look at the top 5 predicted tokens using `torch.topk`.\n",
    "\n",
    "*Check-in: How would we figure out which words those correspond to?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8a3b73f-7ae7-472e-b9e3-09750b4cd695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([28140, 13835,  1824,   352,   309])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_values, top_k_indices = torch.topk(last_token_logits, 5)\n",
    "top_k_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0610c55b-619f-4b82-b63a-aa21c6e8de21",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Decoding our tokens\n",
    "\n",
    "- We can use `tokenizer.convert_ids_to_tokens` to figure out what those tokens actually are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f65f318-5830-48f9-bee6-589f52b86124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ġvinegar', 'Ġpepper', 'Ġwater', 'Ġit', 'ĠI']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(top_k_indices.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814d5db3-54c0-4eb9-b856-2ba0ca010db1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Calculating the probability assigned to those tokens\n",
    "\n",
    "- The **logits** are not equivalent to probability.\n",
    "- We can *convert* logits to probability using the `softmax` operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ab34878-5fca-4c81-909b-f92414df7251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_token_probs = torch.softmax(last_token_logits, dim=0)\n",
    "last_token_probs.sum() ### now they sum to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87f7e8a8-debc-4c00-83c7-d4646acf50ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1769, 0.1281, 0.0337, 0.0310, 0.0277])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Probability of those tokens\n",
    "top_pred_prob = last_token_probs[top_k_indices]\n",
    "top_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71c10767-cc05-406e-ae23-c743917cf446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ġvinegar', 'Ġpepper', 'Ġwater', 'Ġit', 'ĠI']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Reminder of what those tokens are...\n",
    "tokenizer.convert_ids_to_tokens(top_k_indices.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1e46b9-604e-4b28-900b-362e26977943",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Calculating the probability of *specific tokens*\n",
    "\n",
    "- Often, we don't just want to know what word comes next.\n",
    "- We might want to know the probability assigned to *specific tokens* at a *specific position*.\n",
    "- For that, we can use this handy function I've written called `next_seq_prob`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "988d1a01-24fb-480b-a032-1e9a23d24e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_seq_prob(model, tokenizer, seen, unseen):\n",
    "    \"\"\"Get p(unseen | seen)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : transformers.PreTrainedModel\n",
    "        Model to use for predicting tokens\n",
    "    tokenizer : transformers.PreTrainedTokenizer\n",
    "        Tokenizer for Model\n",
    "    seen : str\n",
    "        Input sequence\n",
    "    unseen: str\n",
    "        The sequence for which to calculate a probability\n",
    "    \"\"\"\n",
    "    # Get ids for tokens\n",
    "    input_ids = tokenizer.encode(seen, return_tensors=\"pt\")\n",
    "    unseen_ids = tokenizer.encode(unseen)\n",
    "\n",
    "    # Loop through unseen tokens & store log probs\n",
    "    log_probs = []\n",
    "    for unseen_id in unseen_ids:\n",
    "\n",
    "        # Run model on input\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_ids).logits\n",
    "\n",
    "        # Get next token prediction logits\n",
    "        next_token_logits = logits[0, -1]\n",
    "        next_token_probs = torch.softmax(next_token_logits, 0) # Normalize\n",
    "\n",
    "        # Get probability for relevant token in unseen string & store\n",
    "        prob = next_token_probs[unseen_id]\n",
    "        log_probs.append(torch.log(prob))\n",
    "\n",
    "        # Add input tokens incrementally to input\n",
    "        input_ids = torch.cat((input_ids, torch.tensor([[unseen_id]])), 1)\n",
    "\n",
    "    # Add log probs together to get total log probability of sequence\n",
    "    total_log_prob = sum(log_probs)\n",
    "    # Exponentiate to return to probabilities\n",
    "    total_prob = torch.exp(total_log_prob)\n",
    "    return total_prob.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a564395c-a7df-49d2-8c4d-5ba172e39e34",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Using our `next_seq_prob` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1706aed4-79d0-47a2-ad36-1fc47c08ef50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2902168035507202"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### cats and...dogs\n",
    "next_seq_prob(model, tokenizer, \"I like cats and\", \" dogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a55fc880-46ef-4461-81fc-461d5d2bf2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00196227990090847"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### cats and...lizards\n",
    "next_seq_prob(model, tokenizer, \"I like cats and\", \" lizards\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8167d446-7bf6-49ff-92db-2de3aaf1c23d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Check-in\n",
    "\n",
    "Try to identify other words that would be either *likely* or *unlikely* in this context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d105e8ed-d862-407b-a569-8228051120a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2a92eb-8ada-43a0-bb3c-13eaeb1ef217",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Probability vs. surprisal\n",
    "\n",
    "> **Surprisal** is the negative log probability of a word in context.\n",
    "\n",
    "- Researchers often use *surprisal* instead of *raw probability*.\n",
    "- A higher surprisal score means the model assigned *lower probability* to that word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "069ef2ff-a55f-4b93-ade7-8a14bf118558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def surprisal(x):\n",
    "    return -np.log(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76a2f9a8-c123-4a69-a6cc-89033629f5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.912023005428146"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surprisal(.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ad3529c-fc98-4d1e-a941-211e59aefe27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10536051565782628"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surprisal(.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a85c5c6-c9be-4e38-a050-77ab93256c2c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Surprisal in action\n",
    "\n",
    "- Researchers often compare the surprisal of an *expected* vs. *unexpected* token.\n",
    "- *Example*: sensitivity to *grammatical* vs. *ungrammatical* sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5769712b-c6f6-4780-b208-8e8015fde8fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.458002945185585"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Grammatical\n",
    "surprisal(next_seq_prob(model, tokenizer, \"The keys\", \" are\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bace1a71-aae0-4774-bc41-57891dfaeb28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.236811674957567"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Ungrammatical\n",
    "surprisal(next_seq_prob(model, tokenizer, \"The keys\", \" is\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9256ba-69af-43a5-a521-a99fa409b102",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Check-in\n",
    "\n",
    "Can you create a list of grammatical vs. ungrammatical sentences using **subject-verb agreement** (i.e., singular noun, singular verb; or plural noun, plural verb), and test for sensitivity this distinction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7389590f-5a62-47d0-8500-77f4204d686a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b9f6f4-14ce-4f21-b526-9c958c228e90",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Probability all the way down\n",
    "\n",
    "- With careful **experimental design**, you can use *surprisal* as an index into what an LM knows and doesn't know.\n",
    "- Many examples:\n",
    "   - Grammatical vs. ungrammatical sentences. \n",
    "   - Plausible vs. implausible scenarios.\n",
    "   - True vs. false beliefs (e.g., Theory of Mind).\n",
    "   - Correct vs. incorrect answer (e.g., on a test).\n",
    "\n",
    "Can you think of any others?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8ff5ec-5426-4363-8cf4-3bcadda846fb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Inspecting the `hidden_states`\n",
    "\n",
    "> The **hidden states** are vectors of \"activations\" for each token of each layer of the model.\n",
    "\n",
    "- Our model has *12* layers, plus the initial embedding layer.\n",
    "- This particular model has a $768$-D vector for each token at each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa918581-997b-48ac-a5ae-7b19bb6cba3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: I like salt and\n",
      "Token IDs: tensor([[  42,  751, 7043,  285]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentence: \" + sentence)\n",
    "print(\"Token IDs:\", inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5335b088-9f45-42f2-9a16-f3976cdd0a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Hidden states for each layer\n",
    "len(output.hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b644cfad-b63c-494d-84e3-71c7cd304817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 768])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Size of hidden state at each layer\n",
    "output.hidden_states[3].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3c892c-bb80-474e-9e44-89e37882dece",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Comparing hidden states (1)\n",
    "\n",
    "One way to demonstrate the **hidden state activations** is to compare the representations for the same *word* in different contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "729cdc45-de73-468a-870e-be5f660e808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tokenize phrases\n",
    "c1 = tokenizer(\"marinated lamb\", return_tensors=\"pt\")\n",
    "c2 = tokenizer(\"roasted lamb\", return_tensors=\"pt\")\n",
    "c3 = tokenizer(\"friendly lamb\",  return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6bbdbf18-f0d3-4b7d-882b-0aeb9e5ad07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run through model\n",
    "with torch.no_grad():\n",
    "    o1 = model(**c1)\n",
    "    o2 = model(**c2)\n",
    "    o3 = model(**c3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25814ec9-f86b-4929-873f-a7a91a8dc35c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Comparing hidden states (2)\n",
    "\n",
    "One way to demonstrate the **hidden state activations** is to compare the representations for the same *word* in different contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "73060506-3c4d-4e91-b6ee-af489be53b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "066afd77-aef1-49fa-aaaf-efb4885b5e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Last layer, first batch, last token\n",
    "e1 = o1.hidden_states[12][0][-1]\n",
    "e2 = o2.hidden_states[12][0][-1]\n",
    "e3 = o3.hidden_states[12][0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0e54a82f-031c-439e-b55b-fba796d67ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00295881561174427"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine(e1, e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8e33c49f-6bdf-4cd5-8bae-967b7744f99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004162431863919069"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine(e1, e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "29000b2b-6782-4618-b7f6-daa8f0901900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004779704677303598"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine(e2, e3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18a9206-f149-4cb1-9346-3be4ba197cbd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Inspecting the `attentions`\n",
    "\n",
    "> The **attention scores** are vectors of *attention* from each token to every other token, for each head in each model layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e81044c8-d501-4cc5-b07c-5266b53a2d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 4, 4])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Attention for layer 1:\n",
    "output.attentions[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a49ef3d-520a-4945-a3ba-79c217611f88",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Plotting the attention distribution\n",
    "\n",
    "Let's zoom in on the attention for a specific **head/layer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "406c4ea3-6bee-4e1c-afb9-f7ddd4fea344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_idx, head_idx = 3, 1\n",
    "attn_matrix = output.attentions[layer_idx][0, head_idx]\n",
    "attn_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cf0e7ef6-d03d-45eb-ab54-8dcdef5c06e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Tokens to plot\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "sns.heatmap(attn_matrix.cpu().detach().numpy(),\n",
    "            xticklabels=tokens,\n",
    "            yticklabels=tokens,\n",
    "            cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15309431-f506-46ed-9e85-90604c3c93e3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Generating text!\n",
    "\n",
    "- Finally, we can use the `generate` function to *sample* new tokens.\n",
    "- `max_length`: maximum number of tokens to generate.\n",
    "- By default, `generate` will use **greedy search** (selecting the most likely token)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "082f7c79-49eb-4ad6-a118-f1274e136ff7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[   42,   751,  7043,   285, 28140,    15,   309,  1353,   417,   247,\n",
       "          1943,  7989,   273, 28140,    13,   533,   309,   751,   352,    15,\n",
       "           309,   751,   352,   672,   352,   434,  5352,   285,   352,   434,\n",
       "           417,  1512,  3779,   555,    15,   309,   751,   352,   672,   352]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_output = model.generate(**inputs, max_length=40)\n",
    "gen_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3fef95ad-168e-439f-bfa6-9c2ff9a8333b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I like salt and vinegar. I'm not a big fan of vinegar, but I like it. I like it when it's fresh and it's not too salty. I like it when it\""
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(gen_output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b156b15c-1130-44aa-b0cb-e1f4b84c83c2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Other generation strategies\n",
    "\n",
    "- **Sampling**: rather than selecting the *most likely* token, we sample randomly (weighted by the underlying probability).\n",
    "- **Beam search**: maintain multiple possible strings/branches, then select the one with the highest overall probability.\n",
    "\n",
    "See [HuggingFace's documentation on generation strategies](https://huggingface.co/docs/transformers/en/generation_strategies) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "33b898bb-3962-4d89-9c3f-3aee45555bcd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[   42,   751,  7043,   285, 28140,    15,   313,  2512,   403,   690,\n",
       "          5053,    13,   533,   352,  7024,   327,   849,   368,   751,   352,\n",
       "            10,   187,   187,    42,   717,   970,   253,  1563,  2746,    27,\n",
       "           187,   187,    42,   717,   970,   247,  2505,  8121,   326,   556]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_output = model.generate(**inputs, max_length=40, \n",
    "                            do_sample = True,\n",
    "                           temperature = .7)\n",
    "gen_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "14ddc2dc-d97e-45e6-a429-84c6c99b0704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I like salt and vinegar. (There are some places, but it depends on how you like it)\\n\\nI am using the following approach:\\n\\nI am using a text editor that has'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(gen_output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35c1c44-efab-4ef8-bd76-a54f1ecb7417",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Lecture wrap-up\n",
    "\n",
    "- The `transformers` library is incredibly powerful.\n",
    "- It's also (relatively) straightforward to use, given how powerful it is!\n",
    "- In terms of *using* models, you'll probably want to do one of the following:\n",
    "   - Access `logits`.\n",
    "   - Access `hidden_states`.\n",
    "   - Inspect `attentions`.\n",
    "   - `generate` more text.\n",
    "- Additional **use cases** would include *training* or *fine-tuning* models.\n",
    "- Hopefully you now feel more confident importing and using LLMs!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
