{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8678db24-3c7d-4e8b-84b8-14ce6a652c69",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Support Vector Machines (SVMs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef48023-aa3a-4385-9f76-a97890109e5d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Lecture plan\n",
    "\n",
    "- SVMs: concepts and terminology.\n",
    "  - Margins, hyperplanes, and support vectors.\n",
    "  - Linear vs. non-linear separability.\n",
    "- Using SVMs in `sklearn`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9295bb88-776a-4814-b197-0709f09bfca8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0802c579-d9aa-4bfe-9e48-85135f3c4fcd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'  # makes figs nicer!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71e21f3-6f37-430a-9c9f-1595b6f24e25",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## What is an SVM?\n",
    "\n",
    "> A **Support Vector Machine (SVM)** is a generalization of a *maximal margin classifier*, in which the goal is to draw a **hyperplane** through some feature space separating your data into different classes.\n",
    "\n",
    "- An SVM is a type of *classifier*.\n",
    "- In this section, we'll discuss some key *concepts* that are important for understanding SVMs.\n",
    "   - Hyperplanes.\n",
    "   - Maximal margin classifiers.\n",
    "   - Support vector classifiers.\n",
    "   - Non-linear separability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f30e43-ee12-4bde-9548-f28bf3deec8f",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### What is a *hyperplane*?\n",
    "\n",
    "> In some $p$-dimensional space, a **hyperplane** is a flat subspace of dimension $p-1$.\n",
    "\n",
    "- In a $2D$ space, a hyperplane is just a line.\n",
    "- In a $3D$ space, a hyperplane is a two-dimensional plane.\n",
    "- And so on...though it's very hard to visualize anything past that!\n",
    "\n",
    "In a $2D$ space, a hyperplane is defined by the following linear equation:\n",
    "\n",
    "$$\\beta_0 + \\beta_1X_1 + \\beta_2X_2 = 0$$\n",
    "\n",
    "For any point $(X_1, X_2)$ that satisfies this equation (i.e., $=0$), that point **lies on the hyperplane**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332692cb-f61b-4f1f-ad1f-d80a9b047a8a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Why do we care about hyperplanes?\n",
    "\n",
    "- Many points *won't* lie on the hyperplane.\n",
    "- That means we can treat the hyperplane as a **boundary**.\n",
    "  - Classify points on *one* side as class $K_1$.\n",
    "  - Classify points on the *other* side as class $K_2$.\n",
    "- In the case of a **maximal margin classifier**, we want our hyperplane to maximally separate our classes.\n",
    "\n",
    "<img src=\"img/hyperplane.png\" width=\"300\" alt=\"Hyperplane example\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be7b5a4-cce2-4983-9084-263857da1acf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Finding the best hyperplane\n",
    "\n",
    "- Given two **categories** of observations, there are a number of hyperplanes we might draw to separate them.\n",
    "- Our goal is to fit the hyperplane with the largest **margin** $M$, i.e., the distance between the hyperplane and all of the closest points.\n",
    "\n",
    "<img src=\"img/multiple_hyperplanes.png\" width=\"500\" alt=\"Multiple hyperplanes\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfac960e-61b2-47f4-bec8-ef2204903165",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Margins and support vectors\n",
    "\n",
    "- The **margin** is the distance from the solid line to either of the dashed lines (representing the closest points).\n",
    "- The points closest to the hyperplane are called **support vectors**.\n",
    "   - They \"support\" the hyperplane in that: *if they moved, the hyperplane would also change*.\n",
    "   - The hyperplane really depends only on these support vectors!\n",
    "\n",
    "<img src=\"img/support_vectors.png\" width=\"300\" alt=\"Support vectors\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd50356d-b84c-42e7-851c-e9f9019dfb6f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### A perfect boundary doesn't always exist...\n",
    "\n",
    "- Often, there *doesn't exist* a hyperplane that perfectly separates our classes.\n",
    "- In these cases, we need to relax some of our assumptions.\n",
    "- We'll need to allow for **soft margins**, i.e., some overlap between our classes.\n",
    "- This generalization is called a **support vector classifier**.\n",
    "\n",
    "<img src=\"img/soft_margin.png\" width=\"300\" alt=\"Soft margin\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0946d70b-884d-4371-9ea1-95da8c5f1c12",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Support vector classifiers, explained\n",
    "\n",
    "> A **support vector classifier** (or *soft margin classifier*) classifies a test observation based on which side of the hyperplane it lies.\n",
    "\n",
    "The SVC is a solution to the following constraints:\n",
    "\n",
    "- Maximize $M$, i.e., **margin**.\n",
    "- Subject to $\\sum_{j=1}^p\\beta_j^2=1$, i.e., sum of squared coefficients equals $1$.\n",
    "- Allowing for some **slack variables** $\\epsilon_1, ..., \\epsilon_n$ that can end up on the wrong side of the classifier.\n",
    "   - A tuning parameter $C$ determines how many of these were allow (i.e., our **budget** for misclassifications).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22cb3a7-3fea-49e8-90c0-d02bb5e1ca7d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Check-in: the role of $C$\n",
    "\n",
    "The parameter $C$ is a *budget* for how many misclassifications we allow when fitting our hyperplane. How might this relate to the bias-variance trade-off?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1dc28c-5346-4c56-a2b7-2bf9b5d87753",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### $C$ and the bias-variance trade-off\n",
    "\n",
    "- If $C = 0$, we have no budget, i.e., it's a simple *maximal margin classifier*.\n",
    "  - Ends up with classifier **highly fit to training data**.\n",
    "  - High variance, low bias.\n",
    "- A large $C$ means a more tolerant fit.\n",
    "  - Low variance, higher bias.\n",
    "\n",
    "Recall that only the **support vectors** affect the margin/hyperplane. $C$ essentially controls how many support vectors we care about."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977ff59a-836d-42e9-a1e0-4f9f4023cdbf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Illustrating the role of $C$\n",
    "\n",
    "- A large $C$ (top left) results in larger margin.\n",
    "- A small $C$ (bottom right) results in smaller margin.\n",
    "- The size of the margin determines how many points are considered in drawing the hyperplane, i.e., the **support vectors**!\n",
    "\n",
    "<img src=\"img/margins_budget.png\" width=\"300\" alt=\"Tuning parameter\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95f3a28-e4d9-435f-a5f7-ac2b5c69095f",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Support vector classifiers: an interim summary\n",
    "\n",
    "- Our goal: classify data into categories.\n",
    "- The *how*: draw a **hyperplane** separating the feature-space into classes.\n",
    "  - The **margin** of the hyperplane is the distance to the nearest points.\n",
    "  - Technically, only the nearest points (the **support vectors**) affect the maximal margin classifier.\n",
    "- A support vector classifier allows for **soft margins**, which decrease variance and make more robust models.\n",
    "\n",
    "So far, however, we've only considered classes with a *linear* decision boundary..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24073824-4015-44b4-8561-6f1b995aa6b4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### The problem of non-linear separability\n",
    "\n",
    "> [Linear separability](https://en.wikipedia.org/wiki/Linear_separability) means that two sets of points can be separated drawing a line (or flat hyperplane). **Non-linear** separability is when this is not the case!\n",
    "\n",
    "In some cases, it's impossible to separate our categories with a linear boundary.\n",
    "\n",
    "<img src=\"img/non_linear_separability.png\" width=\"500\" alt=\"The problem of non-linear separability\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8509653-5a8f-4bf3-99e8-d78aa87965f4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Analogy: polynomial regression regression\n",
    "\n",
    "- As discussed in CSS 2, [**polynomial regression**](https://ucsd-css2.github.io/ucsd-css2-website/lectures/16-nonlinear-regression.html) is useful for learning non-linear relationships between $X$ and $Y$.\n",
    "\n",
    "$$Y = \\beta_0 + \\beta_1X_1 + \\beta_2X_1^2 + ... \\beta_pX_1^p$$\n",
    "\n",
    "- With polynomial regression, we enter the same feature ($X_1$) multiple times in the model, but **transform** the feature into higher-order polynomials.\n",
    "   - We then **fit the coefficients** using ordinary least squares.\n",
    "- With an SVM, we can apply the same logic to our **decision boundary**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a350477-4726-46f5-b379-176672d1987c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Learning a non-linear decision boundary\n",
    "\n",
    "- As in polynomial regression, we can *enlarge our feature space* using polynomial transformations (i.e., quadratic, cubic, etc.).\n",
    "- In this enlarged feature space, we can fit a linear decision boundary.\n",
    "  - However, in *original* feature space, this decision boundary is non-linear!\n",
    "- The key question is how to enlarge the feature space.\n",
    "- This is called the **kernel trick**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323037d3-2a1a-45bb-af30-543a90e01777",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### The \"kernel trick\"\n",
    "\n",
    "> The **kernel trick** maps a lower-dimensional feature-space into a higher-dimensional space, in which a linear decision boundary can be drawn.\n",
    "\n",
    "- E.g., map from $1D$ space to $3D$ space using some **transformation**.\n",
    "   - Analogy: transforming a single predictor $X_1$ using cubic regression.\n",
    "- People tend to use one of three kernels:\n",
    "   - **Linear kernel**: linear projection, cannot handle non-linear decision boundaries.\n",
    "   - **Polynomial kernel**: non-linear projection, analogous to polynomial regression.\n",
    "   - **Radial basis function kernel**: another kind of non-linear projection, technically infinite feature space.\n",
    "- Tends to be more computationally efficient than just transforming the features themselves.\n",
    "   - Involves computing *inner product* of pairs of data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d69cac-2657-4699-8da9-7686cffde9be",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### The kernel trick works!\n",
    "\n",
    "- A *linear kernel projection* (left) will fail to separate non-linearly separable data.\n",
    "- But a **non-linear kernel projection** (right: radial basis function) will more often succeed.\n",
    "\n",
    "<img src=\"img/kernel_trick.png\" width=\"500\" alt=\"The non-linear kernel trick works\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2448d1e7-0dbb-4c7c-91ba-400ab5d445e7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Summing up: where do we stand?\n",
    "\n",
    "- We've discussed a few key concepts:\n",
    "   - **Hyperplane**: draw this to separate your classes.\n",
    "   - **Margin**: distance from hyperplane to the nearest points.\n",
    "   - **Support vectors**: the points that actually affect the position of the hyperplane.\n",
    "   - **Non-linear separability**: when two clusters of points can't be separated with a linear decision boundary.\n",
    "   - **Kernel trick**: a way to *project* data into a higher-dimensional space; non-linear kernel tricks allow you to solve non-linearly separable problems.\n",
    "- Putting it altogether...\n",
    "\n",
    "> A **support vector machine (SVM)** is a type of classifier that uses kernel tricks to draw hyperplanes that solve either linearly or non-linearly separable problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950bd2c4-35cd-4fc1-a632-209c155fc411",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## SVMs in practice\n",
    "\n",
    "- Now that we've discussed the conceptual background, we can review the `sklearn` implementation.\n",
    "- [`sklearn.svm.SVC`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) is the relevant class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0120c3a-ac82-47ec-ab96-5a785c714d8b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### The `sklearn` implementation\n",
    "\n",
    "- The [`SVC`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) class can be used to fit linear or non-linear kernels.\n",
    "- Like other `sklearn` models, uses `.fit(X, y)` and `.predict(X)` syntax.\n",
    "- Relevant parameters:\n",
    "   - `C`: regularization parameter, determines *tolerance* for margin errors.\n",
    "      - In `sklearn` implementation, `C` is *inversely proportional* to degree of regularization.\n",
    "      - Larger value = less regularization.\n",
    "   - `kernel`: e.g., *linear* vs. *poly* vs. *rbf*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a2b84ba-043f-42e1-8c6f-80fc72dd2158",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da542a4d-65c7-4dc4-88be-c3808459e648",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### A sample dataset\n",
    "\n",
    "- Let's return to our heart dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "865a03af-52f2-4664-b325-62e38d1fa8c7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPain</th>\n",
       "      <th>RestBP</th>\n",
       "      <th>Chol</th>\n",
       "      <th>Fbs</th>\n",
       "      <th>RestECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExAng</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Thal</th>\n",
       "      <th>AHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>typical</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fixed</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reversable</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Age  Sex     ChestPain  RestBP  Chol  Fbs  RestECG  MaxHR  \\\n",
       "0           1   63    1       typical     145   233    1        2    150   \n",
       "1           2   67    1  asymptomatic     160   286    0        2    108   \n",
       "2           3   67    1  asymptomatic     120   229    0        2    129   \n",
       "\n",
       "   ExAng  Oldpeak  Slope   Ca        Thal  AHD  \n",
       "0      0      2.3      3  0.0       fixed   No  \n",
       "1      1      1.5      2  3.0      normal  Yes  \n",
       "2      1      2.6      2  2.0  reversable  Yes  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_heart = pd.read_csv(\"data/classification/heart.csv\")\n",
    "df_heart.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6f04c9f-acb1-4e93-b0b4-3dc63a716d62",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Relevant features\n",
    "X = df_heart[['MaxHR', 'Chol', 'Age']]\n",
    "y = df_heart['AHD'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae65312-c1d7-465f-8ae3-9e0e201bdadf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Using `train_test_split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5b64a67-2b5b-448c-b0bf-6c811d40200f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec6c44c0-3967-4ce0-898e-6cb86f59c3c5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8475467-0dce-4f63-9535-403de88d6aaa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Creating our `SVC` classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cf1cf05-3165-4070-9399-b91822bea5e4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Create different models\n",
    "linear_svc = SVC(kernel='linear')\n",
    "radial_svc = SVC(kernel = 'rbf')\n",
    "polynomial_svc = SVC(kernel = 'poly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0b51326-430c-4dd2-b437-0b8438139461",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;poly&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(kernel=&#x27;poly&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='poly')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Fit them\n",
    "linear_svc.fit(X_train, y_train)\n",
    "radial_svc.fit(X_train, y_train)\n",
    "polynomial_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29c05f8-b39e-447b-b32f-895a89328869",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Evaluating our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de2e04b0-ad14-4e42-b655-840c91e03b62",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "649c37f0-6251-46e0-a7f5-ad93575df028",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred_linear = linear_svc.predict(X_test)\n",
    "y_pred_radial = radial_svc.predict(X_test)\n",
    "y_pred_polynomial = polynomial_svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c93d5cf3-f13d-491f-8931-4ca6215f05eb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.64\n",
      "0.66\n",
      "0.64\n"
     ]
    }
   ],
   "source": [
    "### In this case, radial is best\n",
    "print(accuracy_score(y_test, y_pred_linear))\n",
    "print(accuracy_score(y_test, y_pred_radial))\n",
    "print(accuracy_score(y_test, y_pred_polynomial))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a19bc13-1a3a-4f63-b349-37f75f590fad",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Which kernel to use?\n",
    "\n",
    "- In practice, which **kernel trick** to use depends on your data.\n",
    "   - Strategy 1: look at your data, try to estimate if classifier should be non-linear.\n",
    "   - Strategy 2: empirical——fit multiple models and see which is best!\n",
    "- The same applies to $C$.\n",
    "   - Like with $\\lambda$, can be **tuned** using cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ec008f-bb32-45c9-bd3a-30f21d545e8e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Lecture wrap-up\n",
    "\n",
    "- Support vector machines are a kind of **classification method**.\n",
    "- Use linear or non-linear **kernel tricks** to project data to some higher-dimensional space, in which they draw a **hyperplane** separating the classes.\n",
    "- Use `sklearn.svm.SVC` for Python implementation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
